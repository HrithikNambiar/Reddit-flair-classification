{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4.2 NLP - HRITHIK NAMBAR\n",
    "#REDDIT FLAIR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import os, sys\n",
    "import re\n",
    "import string\n",
    "import pathlib\n",
    "import random\n",
    "from collections import Counter, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post</th>\n",
       "      <th>Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netflix the family has been an amazing watch d...</td>\n",
       "      <td>netflixs new series the family is about a secr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all results are out is iiitm gwalior it branch...</td>\n",
       "      <td>the internet seems to think so average package...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which are the things you always buy made in india</td>\n",
       "      <td>you can include the reason for your preference...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekly coders hackers amp all tech related thr...</td>\n",
       "      <td>last week issue all threads every week on frid...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are some good unknown companies to work a...</td>\n",
       "      <td>there are similar posts on other subreddits bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is tinder worth my time</td>\n",
       "      <td>i heard a lot about it from my friends and col...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is there a progressive political party in indi...</td>\n",
       "      <td>i am an american i vote progressive democrat i...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rindia father heavily depressed situation is r...</td>\n",
       "      <td>father took a big loan couldn pay amount kept ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what to do when more than mrp was charged in f...</td>\n",
       "      <td>hello i had ordered a perfume for which costed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>app for expense tracking budgeting financial a...</td>\n",
       "      <td>need recommendations for an app which is both ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  netflix the family has been an amazing watch d...   \n",
       "1  all results are out is iiitm gwalior it branch...   \n",
       "2  which are the things you always buy made in india   \n",
       "3  weekly coders hackers amp all tech related thr...   \n",
       "4  what are some good unknown companies to work a...   \n",
       "5                            is tinder worth my time   \n",
       "6  is there a progressive political party in indi...   \n",
       "7  rindia father heavily depressed situation is r...   \n",
       "8  what to do when more than mrp was charged in f...   \n",
       "9  app for expense tracking budgeting financial a...   \n",
       "\n",
       "                                                Post  Flair  \n",
       "0  netflixs new series the family is about a secr...     10  \n",
       "1  the internet seems to think so average package...      0  \n",
       "2  you can include the reason for your preference...      0  \n",
       "3  last week issue all threads every week on frid...     11  \n",
       "4  there are similar posts on other subreddits bu...      0  \n",
       "5  i heard a lot about it from my friends and col...      0  \n",
       "6  i am an american i vote progressive democrat i...     10  \n",
       "7  father took a big loan couldn pay amount kept ...      7  \n",
       "8  hello i had ordered a perfume for which costed...      0  \n",
       "9  need recommendations for an app which is both ...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.txt\")\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Flair\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'AskIndia',\n",
       " 1: 'Business/Finance',\n",
       " 2: 'CAA-NRC',\n",
       " 3: 'Coronavirus',\n",
       " 4: 'Demonetization',\n",
       " 5: 'Entertainment',\n",
       " 6: 'Food',\n",
       " 7: 'Non-Political',\n",
       " 8: 'Photography',\n",
       " 9: 'Policy/Economy',\n",
       " 10: 'Politics',\n",
       " 11: 'Scheduled',\n",
       " 12: 'Science/Technology',\n",
       " 13: 'Sports',\n",
       " 14: '[R]eddiquette'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id={\"AskIndia\": 0, \"Business/Finance\": 1, \"CAA-NRC\": 2, \"Coronavirus\": 3, \"Demonetization\": 4, \"Entertainment\": 5, \"Food\": 6, \"Non-Political\": 7, \"Photography\": 8, \"Policy/Economy\": 9, \"Politics\": 10, \"Scheduled\": 11, \"Science/Technology\": 12, \"Sports\": 13, \"[R]eddiquette\": 14}\n",
    "id_to_label={v: k for k, v in label_to_id.items()}\n",
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "#flairs = [‘AskIndia’, ‘Business/Finance’, ‘CAA-NRC’, ‘Coronavirus’, ‘Demonetization’, ‘Entertainment’, ‘Food’, ‘Non-Political’, ‘Photography’, ‘Policy/Economy’, ‘Politics’, ‘Scheduled’, ‘Science/Technology’, ‘Sports’, ‘[R]eddiquette’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  16616\n",
      "1 :  811\n",
      "2 :  76\n",
      "3 :  793\n",
      "4 :  365\n",
      "5 :  172\n",
      "6 :  293\n",
      "7 :  8118\n",
      "8 :  96\n",
      "9 :  1046\n",
      "10 :  4847\n",
      "11 :  580\n",
      "12 :  961\n",
      "13 :  256\n",
      "14 :  1517\n"
     ]
    }
   ],
   "source": [
    "for flair in id_to_label:\n",
    "    print (flair,': ' , len(train[train['Flair'] == flair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  4092\n",
      "1 :  200\n",
      "2 :  19\n",
      "3 :  196\n",
      "4 :  90\n",
      "5 :  42\n",
      "6 :  72\n",
      "7 :  1999\n",
      "8 :  24\n",
      "9 :  257\n",
      "10 :  1194\n",
      "11 :  143\n",
      "12 :  236\n",
      "13 :  63\n",
      "14 :  374\n"
     ]
    }
   ],
   "source": [
    "val = pd.read_csv(\"val.txt\")\n",
    "for flair in flairs:\n",
    "    print (flair,': ' , len(val[val['Flair'] == flair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we replace removed, nan or deleted text in selftext with an empty character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 238\n",
      "[deleted] 0\n",
      "[removed] 0\n"
     ]
    }
   ],
   "source": [
    "train['Post'] = train['Post'].astype(str)\n",
    "val['Post'] = val['Post'].astype(str)\n",
    "\n",
    "empties = ['nan', '[deleted]', '[removed]']\n",
    "for empty in empties:\n",
    "  print(empty, len(train[train['Post'] == empty]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['Post'] = train['Post'].apply(lambda x: '' if x in empties else x)\n",
    "val['Post'] = val['Post'].apply(lambda x: '' if x in empties else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0\n",
      "[deleted] 0\n",
      "[removed] 0\n"
     ]
    }
   ],
   "source": [
    "empties = ['nan', '[deleted]', '[removed]']\n",
    "for empty in empties:\n",
    "  print(empty, len(train[train['Post'] == empty]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us merge the title and post since they describe the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'] + ' ' + train['Post']\n",
    "val['Title'] = val['Title'] + ' ' + val['Post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(s): \n",
    "    return [w.text.lower() for w in nlp(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Post']\n",
    "train, val = train.drop(cols, axis=1), val.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netflix the family has been an amazing watch d...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all results are out is iiitm gwalior it branch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which are the things you always buy made in in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weekly coders hackers amp all tech related thr...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are some good unknown companies to work a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Flair\n",
       "0  netflix the family has been an amazing watch d...     10\n",
       "1  all results are out is iiitm gwalior it branch...      0\n",
       "2  which are the things you always buy made in in...      0\n",
       "3  weekly coders hackers amp all tech related thr...     11\n",
       "4  what are some good unknown companies to work a...      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False);val.to_csv('val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_field = data.Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)\n",
    "text_field = data.Field(sequential=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\n",
    "\n",
    "train_val_fields = [\n",
    "     ('Title', text_field),\n",
    "    ('flairs', label_field)\n",
    "   \n",
    "]\n",
    "\n",
    "trainds, valds = data.TabularDataset.splits(path='./', format='csv', train='train.csv', \n",
    "                validation='val.csv', fields=train_val_fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_GloVe_sizes = [50, 100, 200, 300]\n",
    "\n",
    "def load_pretrained_vectors(dim):\n",
    "    if dim in pretrained_GloVe_sizes:\n",
    "        # for other pretrained vectors. 6B used here\n",
    "        name = 'glove.{}.{}d'.format('6B', str(dim))\n",
    "        return name\n",
    "    return None\n",
    "\n",
    "vectors = load_pretrained_vectors(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(trainds, valds, max_size=100000, vectors=vectors)\n",
    "label_field.build_vocab(trainds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100002, 300])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>netflix the family has been an amazing watch d...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Flair\n",
       "0  netflix the family has been an amazing watch d...     10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 201988), ('to', 157891), ('i', 143063), ('and', 136361), ('a', 115617), ('of', 110392), ('in', 98378), ('is', 79377), ('for', 62627), ('it', 60650)]\n",
      "[('0', 16616), ('7', 8118), ('10', 4847), ('14', 1517), ('9', 1046), ('12', 961), ('1', 811), ('3', 793), ('11', 580), ('4', 365)]\n"
     ]
    }
   ],
   "source": [
    "print (text_field.vocab.freqs.most_common(10))\n",
    "print (label_field.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we build RNN/LSTM based models for flair classification task.  \n",
    "#we input the concatenation of title and body of the post and try to predict flair using a softmax classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(text_field.vocab)\n",
    "embedding_dim = 300\n",
    "n_hidden = 128\n",
    "n_out = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we have a LSTM or GRU encoder for the embedded input sequence\n",
    "#Here we have a context vector(attention mechanism) conditioned over the hidden states of the GRU or LSTM\n",
    "#First we have a LSTM or GRU encoder for the embedded input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNS = ['LSTM', 'GRU']\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  \n",
    "  def __init__(self, embedding_dim, hidden_dim, nlayers=1, dropout=0.,bidirectional=True, rnn_type='GRU'):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.bidirectional = bidirectional\n",
    "    assert rnn_type in RNNS, 'Use one of the following: {}'.format(str(RNNS))\n",
    "    rnn_cell = getattr(nn, rnn_type)\n",
    "    self.rnn = rnn_cell(embedding_dim, hidden_dim, nlayers, \n",
    "                        dropout=dropout, bidirectional=bidirectional)\n",
    "  \n",
    "  def forward(self, input, hidden=None):\n",
    "    return self.rnn(input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention layer\n",
    "#We then perform a Scaled dot-product,self-attention with the encoder outputs as keys and values and the hidden state as the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "  \n",
    "  def __init__(self, query_dim, key_dim, value_dim):\n",
    "    super(Attention, self).__init__()\n",
    "    self.scale = 1. / math.sqrt(query_dim)\n",
    "  \n",
    "\n",
    "  def forward(self, query, keys, values):\n",
    "    query = query.unsqueeze(1)\n",
    "    keys = keys.transpose(0,1).transpose(1,2)\n",
    "    energy = torch.bmm(query, keys) \n",
    "    energy = F.softmax(energy.mul_(self.scale), dim=2) \n",
    "\n",
    "    values = values.transpose(0,1)\n",
    "    linear_combination = torch.bmm(energy, values).squeeze(1) \n",
    "    return energy, linear_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a softmax classifier on top of the attention outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  \n",
    " def __init__(self, embedding, encoder, attention, hidden_dim, num_classes):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.embedding = embedding\n",
    "    self.encoder = encoder\n",
    "    self.attention = attention\n",
    "    self.decoder = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    size = 0\n",
    "    for p in self.parameters():\n",
    "        size += p.nelement()\n",
    "    print('Total param size: {}'.format(size))\n",
    "\n",
    "  \n",
    "\n",
    " def forward(self, input):\n",
    "    outputs, hidden = self.encoder(self.embedding(input))\n",
    "    if isinstance(hidden, tuple):\n",
    "        hidden = hidden[1]\n",
    "\n",
    "    if self.encoder.bidirectional:\n",
    "        hidden = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "    else:\n",
    "        hidden = hidden[-1]\n",
    "\n",
    "    energy, linear_combination = self.attention(hidden, outputs, outputs) \n",
    "    logits = self.decoder(linear_combination)\n",
    "    return logits, energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed, cuda=False):\n",
    "  # Set the random seed manually for reproducibility.\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def acc(accuracy, logits, y):\n",
    "    _, max_ind = torch.max(logits, 1)\n",
    "    equal = torch.eq(max_ind, y)\n",
    "    correct = int(torch.sum(equal))\n",
    "    return accuracy + correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training: Takes in the model, optimizer(Adam), dataloader, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, trainiter, valiter, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_accuracy = 0\n",
    "    t = time.time()\n",
    "    train_total_loss = 0\n",
    "    for batch_num, batch in enumerate(trainiter):\n",
    "        model.zero_grad()\n",
    "        x, lens = batch.Title\n",
    "        y = batch.flairs\n",
    "        logits, _ = model(x)\n",
    "        loss = criterion(logits.view(-1, 15), y)\n",
    "        train_total_loss += float(loss)\n",
    "        train_accuracy = acc(train_accuracy, logits, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    t = time.time()\n",
    "    val_total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, batch in enumerate(valiter):\n",
    "            x, lens = batch.Title\n",
    "            y = batch.flairs\n",
    "            logits, _ = model(x)\n",
    "            val_total_loss += float(criterion(logits.view(-1, 15), y))\n",
    "            val_accuracy = acc(val_accuracy, logits, y)    \n",
    "        t = time.time()\n",
    "\n",
    "    train_lo = (train_total_loss / len(trainiter))\n",
    "    train_acc = (train_accuracy / len(trainiter.dataset))\n",
    "    val_lo = (val_total_loss / len(valiter))\n",
    "    val_acc = (val_accuracy / len(valiter.dataset))\n",
    "  \n",
    "    print(f'Epoch {epoch}: train_loss: {train_lo:.4f} train_acc: {train_acc:.4f} | val_loss: {val_lo:.4f} val_acc: {val_acc:.4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\") if not cuda else torch.device(\"cuda:0\")\n",
    "seed_everything(seed=1337, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds), \n",
    "                                            batch_size=batch_size, \n",
    "                                            sort_key=lambda x: len(x.Title), \n",
    "                                            device=device, \n",
    "                                            sort_within_batch=True, \n",
    "                                            repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = traindl, valdl\n",
    "TEXT, LABEL = text_field, label_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Corpus]: train: 36547, test: 9001, vocab: 100002, labels: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"[Corpus]: train: {}, test: {}, vocab: {}, labels: {}\".format(\n",
    "            len(train_iter.dataset), len(val_iter.dataset), len(TEXT.vocab), len(LABEL.vocab)))\n",
    "\n",
    "ntokens, nlabels = len(TEXT.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#Hyperparameters\n",
    "emsize = 300\n",
    "hidden = 64\n",
    "nlayers = 2\n",
    "lr = 1e-3\n",
    "clip = 0.25\n",
    "epochs = 3\n",
    "drop = 0.6\n",
    "model = 'GRU'\n",
    "bi = True\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total param size: 30217575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (embedding): Embedding(100002, 300, padding_idx=1, max_norm=1)\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(300, 64, num_layers=2, dropout=0.6, bidirectional=True)\n",
       "  )\n",
       "  (attention): Attention()\n",
       "  (decoder): Linear(in_features=128, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(ntokens, emsize, padding_idx=1, max_norm=1)\n",
    "if vectors: \n",
    "    embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "encoder = Encoder(emsize, hidden, nlayers=nlayers, \n",
    "                  dropout=drop, bidirectional=bi, rnn_type=model)\n",
    "\n",
    "attention_dim = hidden if not bi else 2*hidden\n",
    "attention = Attention(attention_dim, attention_dim, attention_dim)\n",
    "\n",
    "model = Classifier(embedding, encoder, attention, attention_dim, nlabels)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 1.4976 train_acc: 0.5297 | val_loss: 1.2788 val_acc: 0.6088\n",
      "Epoch 2: train_loss: 1.0776 train_acc: 0.6625 | val_loss: 1.2670 val_acc: 0.5994\n",
      "Epoch 3: train_loss: 0.7418 train_acc: 0.7659 | val_loss: 1.4815 val_acc: 0.5733\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    m = train(epoch, model, train_iter, val_iter, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of 57.33% is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
